{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paradox20029/computational_intelligence/blob/main/SIT215_Prac_Week1_(2)_agents_env_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **SIT215 WEEK 1 Practical (Workshop)**"
      ],
      "metadata": {
        "id": "8Wf0YXo93DHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent and Environment\n",
        "\n",
        "Recall our discussed example in Lectures: Vacuum Cleaner\n",
        "\n",
        "Agents and environments provide a useful framework for understanding and designing intelligent systems. By defining agents and environments, we can start to think about the kinds of tasks that an intelligent system might need to perform, the kinds of sensors and actuators it might need to have, and the kinds of knowledge and reasoning it might need to use to make decisions and take actions.\n",
        "\n",
        "We will study a simple vacuum cleaner agent that lives in a simple environment consisting of a n-location room. Each location can either be clean or dirty. The agent can perceive the state of the current location (clean or dirty) and its own location. The agent can perform two actions: `Suck`, which cleans the current location, and `Left` and `Right`, which move the agent to the other location.\n"
      ],
      "metadata": {
        "id": "kswBIk0uk4Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Discussions]\n",
        "**Questions**\n",
        "1. Stduy the following example, and figure out how many locations will be created for the agent to react with the environment?\n",
        "\n",
        "2. What elements do you identify in the below example implementation for an intelligent system with an agent and environment? What are missing?\n",
        "\n"
      ],
      "metadata": {
        "id": "r9Ja2GXyIBNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Exercise] Environment - The action method in the below environment does not work. Can you fix it?\n",
        "\n",
        "\n",
        "An environment class may include the following elements:\n",
        "\n",
        "* **Constructor**: initializes the environment's internal state when an instance of the class is created.\n",
        "\n",
        "* **Perception methods**: Perception methods are used by the environment to provide sensory data to agents.\n",
        "\n",
        "* **Action methods**: Action methods are used by agents to perform actions in the environment. These methods might include functions to move the agent or manipulate objects in the environment, or to send messages to other agents.\n",
        "\n",
        "* **State variables**: State variables are used by the environment to keep track of the state of objects and events in the environment.\n",
        "\n",
        "* **Communication methods**: Communication methods are used by the environment to enable agents to interact with each other.\n",
        "\n",
        "* **Performance metrics**: Performance metrics are used to evaluate the effectiveness of agents in achieving their goals. These might include measures of success, such as the agent's score or accuracy, or measures of efficiency, such as the agent's speed or resource utilization.\n",
        "\n",
        "* **Visualisation and rendering methods**: Visualisation and rendering methods are used to display the environment to users. These might include functions to render a 2D or 3D representation of the environment.\n",
        "\n",
        "Overall, an environment class should be designed to provide a rich and dynamic environment for agents to operate in. It should be flexible enough to accommodate a wide range of agent types and behaviors, and should be modular and extensible to allow for easy customization and experimentation.\n"
      ],
      "metadata": {
        "id": "Nqa-mlEC7RPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# class VacuumEnvironment:\n",
        "#     def __init__(self, width, height):\n",
        "#         self.width = width\n",
        "#         self.height = height\n",
        "#         self.agent_location = (random.randint(0, width-1), random.randint(0, height-1))\n",
        "#         self.dirt_locations = [(random.randint(0, width-1), random.randint(0, height-1)) for _ in range(random.randint(1, width*height//2))]\n",
        "\n",
        "#     def get_percepts(self):\n",
        "#         return self.agent_location, self.dirt_locations\n",
        "\n",
        "#     def execute_action(self, action):\n",
        "#         x, y = self.agent_location\n",
        "\n",
        "#         if action == 'left':\n",
        "#             self.agent_location = max(0,(x - 1, y)) # Moving left\n",
        "#         elif action == 'right':\n",
        "#             self.agent_location = (min(self.width-1,x-1),y)  # Moving right\n",
        "#         elif action == 'up' and y > 0:\n",
        "#             self.agent_location = (x, y - 1)  # Moving up\n",
        "#         elif action == 'down' and y < self.height - 1:\n",
        "#             self.agent_location = (x, y + 1)  # Moving down\n",
        "#         elif action == 'suck' and self.agent_location in self.dirt_locations:\n",
        "#             self.dirt_locations.remove(self.agent_location)  # Cleaning the dirt\n",
        "\n",
        "#     def measure_performance(self):\n",
        "#         cleaned_locations = (self.width * self.height) - len(self.dirt_locations)\n",
        "#         return cleaned_locations  # Higher value means better performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "We use max() and min() to ensure that the agent never moves outside the environment boundaries.\n",
        "\n",
        "How max() Works in Movement\n",
        "Used when moving left (x decreases) or up (y decreases).\n",
        "Ensures that the agent never goes below 0 (prevents moving outside the grid).\n",
        "'''\n",
        "import random\n",
        "\n",
        "class VacuumEnvironment:\n",
        "    def __init__(self, width, height):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.agent_location = (random.randint(0, width - 1), random.randint(0, height - 1))\n",
        "        self.dirt_locations = set(\n",
        "            (random.randint(0, width - 1), random.randint(0, height - 1))\n",
        "            for _ in range(random.randint(1, (width * height) // 2))\n",
        "        )\n",
        "\n",
        "    def get_percepts(self):\n",
        "        return self.agent_location, self.dirt_locations\n",
        "\n",
        "    def execute_action(self, action):\n",
        "        x, y = self.agent_location\n",
        "\n",
        "        if action == 'left':\n",
        "            self.agent_location = (max(0, x - 1), y)  #  Move left safely\n",
        "        elif action == 'right':\n",
        "            self.agent_location = (min(self.width - 1, x + 1), y)  #  Move right safely ,Ensures x never exceeds width - 1 when moving right\n",
        "        elif action == 'up':\n",
        "            self.agent_location = (x, max(0, y - 1))  #  Move up safely\n",
        "        elif action == 'down':\n",
        "            self.agent_location = (x, min(self.height - 1, y + 1))  #  Move down safely\n",
        "        elif action == 'suck' and self.agent_location in self.dirt_locations:#checks that if agent is still in the environemtn location\n",
        "            self.dirt_locations.remove(self.agent_location)  #  Clean the dirt\n",
        "\n",
        "    def measure_performance(self):\n",
        "        cleaned_locations = (self.width * self.height) - len(self.dirt_locations)\n",
        "        return cleaned_locations  # Higher value means better performance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aO4gN_EY6oP7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = VacuumEnvironment(5, 5)\n",
        "print(env.get_percepts())\n",
        "env.execute_action('right')\n",
        "env.execute_action('down')\n",
        "env.execute_action('suck')\n",
        "print(env.get_percepts())\n",
        "print(env.measure_performance())\n",
        "\n",
        "#============\n",
        "# Example usage\n",
        "env = VacuumEnvironment(5, 5)\n",
        "print(\"Initial Agent Location:\", env.agent_location)\n",
        "print(\"Initial Dirt Locations:\", env.dirt_locations)\n",
        "\n",
        "env.execute_action(\"left\")\n",
        "print(\"Agent Location after moving left:\", env.agent_location)\n",
        "\n",
        "print(\"Dirt Locations after sucking:\", env.dirt_locations)\n",
        "print(\"Performance Measure:\", env.measure_performance())\n"
      ],
      "metadata": {
        "id": "04lBW9oY68v3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c80d5f-fe3e-4963-a0c7-cfbd8ae8c10f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((3, 4), {(2, 4), (0, 4), (4, 3), (0, 3), (2, 3), (1, 0)})\n",
            "((4, 4), {(2, 4), (0, 4), (4, 3), (0, 3), (2, 3), (1, 0)})\n",
            "19\n",
            "Initial Agent Location: (1, 1)\n",
            "Initial Dirt Locations: {(2, 4), (4, 0), (3, 4), (1, 1), (2, 3), (1, 0), (3, 2)}\n",
            "Agent Location after moving left: (0, 1)\n",
            "Dirt Locations after sucking: {(2, 4), (4, 0), (3, 4), (1, 1), (2, 3), (1, 0), (3, 2)}\n",
            "Performance Measure: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Exercise] Agent\n",
        "\n"
      ],
      "metadata": {
        "id": "aAXhu4lT7LEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "An agent class may include the following elements:\n",
        "\n",
        "* **Constructor**: A constructor is a special method that initializes the agent's internal state when an instance of the class is created.\n",
        "\n",
        "* **Perception methods**: Perception methods are used by the agent to gather information about its environment. These methods might include functions to read sensory data, to query the state of other agents or objects in the environment, or to receive messages from other agents.\n",
        "\n",
        "* **Decision-making methods**: Decision-making methods are used by the agent to determine its next action based on its current state and any available information. These methods might include search algorithms, reinforcement learning algorithms, or rule-based systems.\n",
        "\n",
        "* **Action methods**: Action methods are used by the agent to perform actions in its environment. These methods might include functions to move the agent or manipulate objects in the environment, or to send messages to other agents.\n",
        "\n",
        "* **Memory or state variables**: Memory or state variables are used by the agent to keep track of its current state and any relevant information. These might include variables to store sensory data, search state, or learned models.\n",
        "\n",
        "* **Communication methods**: Communication methods are used by the agent to interact with other agents in the environment. These might include functions to send or receive messages, or to negotiate with other agents to achieve common goals.\n",
        "\n",
        "* **Performance metrics**: Performance metrics are used to evaluate the agent's effectiveness in achieving its goals. These might include measures of success, such as the agent's score or accuracy, or measures of efficiency, such as the agent's speed or resource utilization.\n",
        "\n",
        "Overall, an agent class should be designed to encapsulate all of the agent's capabilities and responsibilities within a single, well-defined object. This allows the agent to be easily instantiated and reused in multiple environments or scenarios, and makes it easier to debug and maintain the agent's code over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "k8M6NpfQXLDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Discussions]\n",
        "**Questions**\n",
        "\n",
        "1. What methods are in an `agent` class but not in an `environment` class?\n",
        "\n",
        "\n",
        "2. How is an action method in an environment class different from an action method in an agent class?"
      ],
      "metadata": {
        "id": "N5UJkPLgEm2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-based Reflex Agents\n",
        "\n",
        "We can add internal state to obtain model-based reflex agents. Its current state is a model of the environment and it updates that state based on the actions it takes and the percepts it receives.\n"
      ],
      "metadata": {
        "id": "Fh_BlpXPHIF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [Exercise] Study the below example and fix the data structure that induced the error."
      ],
      "metadata": {
        "id": "BF3dW0dRDUcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBasedReflexVacuumAgent:\n",
        "    def __init__(self, environment):\n",
        "        self.environment = environment\n",
        "        self.state = self.get_percept()\n",
        "\n",
        "    def get_percept(self):\n",
        "        location, dirt_locations = self.environment.get_percepts()\n",
        "        return {'location': location, 'dirt_locations': set(dirt_locations)}\n",
        "\n",
        "    def update_state(self, action, percept):\n",
        "        location, dirt_locations = self.state['location'], self.state['dirt_locations']\n",
        "\n",
        "        if action == 'suck':\n",
        "            dirt_locations.discard(location)\n",
        "        elif action == 'up':\n",
        "            location = (location[0], location[1] - 1)\n",
        "        elif action == 'down':\n",
        "            location = (location[0], location[1] + 1)\n",
        "        elif action == 'left':\n",
        "            location = (location[0] - 1, location[1])\n",
        "        elif action == 'right':\n",
        "            location = (location[0] + 1, location[1])\n",
        "\n",
        "        dirt_locations.update(percept['dirt_locations'])\n",
        "\n",
        "        self.state = {'location': location, 'dirt_locations': dirt_locations}\n",
        "\n",
        "    def choose_action(self):\n",
        "        location, dirt_locations = self.state['location'], self.state['dirt_locations']\n",
        "        if location in dirt_locations:\n",
        "            return 'suck'\n",
        "        else:\n",
        "            x, y = location\n",
        "            if x == 0:\n",
        "                return 'right'\n",
        "            elif x == self.environment.width - 1:\n",
        "                return  'left'\n",
        "            elif y == 0:\n",
        "                return  'down'\n",
        "            elif y == self.environment.height - 1:\n",
        "                return 'up'\n",
        "            else:\n",
        "                return random.choice(['up', 'down', 'left', 'right'])\n",
        "\n",
        "\n",
        "env = VacuumEnvironment(5, 5)\n",
        "\n",
        "agent = ModelBasedReflexVacuumAgent(env)\n",
        "\n",
        "for i in range(10):\n",
        "    percept = agent.get_percept()\n",
        "    print('Percept:', percept)\n",
        "    action = agent.choose_action()\n",
        "    env.execute_action(action)\n",
        "    print('Action:', action)\n",
        "    print('Performance:', env.measure_performance())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uBxVCaMoHvQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06da397e-d03c-426b-a4d9-99b26c63e147"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percept: {'location': (2, 3), 'dirt_locations': {(3, 1)}}\n",
            "Action: down\n",
            "Performance: 24\n",
            "Percept: {'location': (2, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: left\n",
            "Performance: 24\n",
            "Percept: {'location': (1, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: left\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: down\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: left\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: right\n",
            "Performance: 24\n",
            "Percept: {'location': (1, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: left\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 4), 'dirt_locations': {(3, 1)}}\n",
            "Action: up\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 3), 'dirt_locations': {(3, 1)}}\n",
            "Action: left\n",
            "Performance: 24\n",
            "Percept: {'location': (0, 3), 'dirt_locations': {(3, 1)}}\n",
            "Action: up\n",
            "Performance: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [Discussions]\n",
        "**Questions**\n",
        "1. In the given `ModelBasedReflexVacuumAgent`, what constitutes the `internal state (self.state)`?\n",
        "\n",
        "2. How does the `agent` perceive the `environment` and update its internal state??\n"
      ],
      "metadata": {
        "id": "tdUYt8IWCtC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional readings\n",
        "\n",
        "- [Intelligent Agents](https://github.com/aimacode/aima-python/blob/master/agents.ipynb)\n",
        "- [Python list implementation](http://www.laurentluce.com/posts/python-list-implementation/)\n"
      ],
      "metadata": {
        "id": "CKgYkfHPQiKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Your after-class Exercise]\n",
        "\n",
        "1. Review your class discussions and take notes/code comments on the above-mentioned examples to consolidate your understanding."
      ],
      "metadata": {
        "id": "kRGwn9oYLvzQ"
      }
    }
  ]
}